# -*- coding: utf-8 -*-
"""Cliniscan17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BcgF6bY0tJDKM0zu4e7nLyljuvqVJ31X

**CliniScan:Lung-Abnormality Detection on Chest Xâ€‘rays using AI**

**1-DICOM to PNG Conversion Utility**
"""
# app.py
import streamlit as st
import torch
import torch.nn as nn
from torchvision import transforms, models
from PIL import Image
import numpy as np
import io
import cv2
import pandas as pd
import os
import tempfile

# Optional imports that may fail if not installed; we'll handle errors gracefully
try:
    from pytorch_grad_cam import GradCAM
    from pytorch_grad_cam.utils.image import show_cam_on_image
    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
    GRADCAM_AVAILABLE = True
except Exception as e:
    GRADCAM_AVAILABLE = False
    gradcam_import_error = e

# -----------------------
# Utilities: DICOM -> PIL
# -----------------------
import pydicom
from io import BytesIO

def dicom_bytes_to_pil(dcm_bytes):
    """Convert DICOM bytes to a PIL.Image (RGB)."""
    try:
        ds = pydicom.dcmread(BytesIO(dcm_bytes))
        arr = ds.pixel_array
        # Normalize to 0-255
        arr_norm = cv2.normalize(arr, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')
        # If single channel, convert to RGB
        if arr_norm.ndim == 2:
            img = Image.fromarray(arr_norm).convert("RGB")
        else:
            img = Image.fromarray(arr_norm).convert("RGB")
        return img
    except Exception as e:
        raise RuntimeError(f"Failed to parse DICOM: {e}")

# -----------------------
# VinDr dataset class (kept for compatibility)
# -----------------------
from torch.utils.data import Dataset
class VinDrCXRDataset(Dataset):
    def __init__(self, df, img_dir, transform=None, task='classification'):
        self.df = df
        self.img_dir = img_dir
        self.transform = transform
        self.task = task

        self.labels = sorted(df['label'].unique())
        self.label_to_id = {label: i for i, label in enumerate(self.labels)}

        self.grouped_images = self.df.groupby('image_id')
        self.image_ids = list(self.grouped_images.groups.keys())

    def __len__(self):
        return len(self.image_ids)

    def __getitem__(self, idx):
        img_id = self.image_ids[idx]
        img_path = os.path.join(self.img_dir, f"{img_id}.png")
        image = Image.open(img_path).convert("RGB")
        annotations = self.grouped_images.get_group(img_id)

        if self.task == 'classification':
            label_vector = torch.zeros(len(self.labels), dtype=torch.float)
            for _, row in annotations.iterrows():
                label_vector[self.label_to_id[row['label']]] = 1.0

            if self.transform:
                image = self.transform(image)

            return image, label_vector

        elif self.task == 'detection':
            boxes, labels = [], []
            for _, row in annotations.iterrows():
                boxes.append([row['x_min'], row['y_min'], row['x_max'], row['y_max']])
                labels.append(self.label_to_id[row['label']])

            target = {
                'boxes': torch.tensor(boxes, dtype=torch.float32),
                'labels': torch.tensor(labels, dtype=torch.int64)
            }

            if self.transform:
                image = self.transform(image)

            return image, target

# -----------------------
# ResNetClassifier (kept for compatibility with saved state_dict)
# -----------------------
from torchvision.models import resnet18
try:
    # newer torchvision uses ResNet18_Weights
    from torchvision.models import ResNet18_Weights
    RESNET_WEIGHTS = ResNet18_Weights.DEFAULT
except Exception:
    RESNET_WEIGHTS = None

class ResNetClassifier(nn.Module):
    def __init__(self, num_classes=2):
        super(ResNetClassifier, self).__init__()
        try:
            if RESNET_WEIGHTS is not None:
                self.model = resnet18(weights=RESNET_WEIGHTS)
            else:
                self.model = resnet18(pretrained=True)
        except Exception:
            # fallback
            self.model = resnet18(pretrained=True)
        num_ftrs = self.model.fc.in_features
        self.model.fc = nn.Linear(num_ftrs, num_classes)

    def forward(self, x):
        return self.model(x)

# -----------------------
# Model loading helper
# -----------------------
@st.cache_resource
def load_model_from_path(model_path=None, num_classes=2):
    """
    Loads your ResNetClassifier if possible (so saved state_dict matches),
    otherwise falls back to torchvision resnet18 pre-trained model.
    """
    # prefer to build ResNetClassifier (so state dicts saved from your training load)
    model = ResNetClassifier(num_classes=num_classes)
    if model_path:
        try:
            # save uploaded file into a temp file path for torch.load
            sd = torch.load(model_path, map_location="cpu")
            # if the user uploaded an entire model object, sd may not be a state_dict
            if isinstance(sd, dict):
                model.load_state_dict(sd)
            else:
                # maybe the user saved the full model object
                model = sd
            st.success("âœ… model.pth loaded.")
            model.eval()
            return model
        except Exception as e:
            st.warning(f"Could not load provided model.pth into ResNetClassifier: {e}")
            st.info("Falling back to a pretrained ResNet18 with the same number of output neurons.")
    # fallback
    try:
        # create a torchvision resnet and adjust final layer
        try:
            if RESNET_WEIGHTS is not None:
                base = resnet18(weights=RESNET_WEIGHTS)
            else:
                base = resnet18(pretrained=True)
        except Exception:
            base = resnet18(pretrained=True)
        base.fc = nn.Linear(base.fc.in_features, num_classes)
        st.info("Using fallback ResNet18 (ImageNet weights).")
        base.eval()
        return base
    except Exception as e:
        raise RuntimeError(f"Failed to create model: {e}")

# -----------------------
# Preprocessing
# -----------------------
transform = transforms = transforms = transforms = transforms = None
from torchvision import transforms as T
transform = T.Compose([
    T.Resize((224, 224)),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225])
])

# -----------------------
# Streamlit UI
# -----------------------
st.set_page_config(page_title="CliniScan â€” Chest X-Ray (Grad-CAM)", layout="wide")
st.title("ðŸ©» CliniScan â€” Chest X-Ray Classification + Grad-CAM")

with st.sidebar:
    st.header("Options")
    num_classes = st.number_input("Number of classes (model final layer)", value=2, min_value=2, max_value=20)
    upload_model = st.file_uploader("Upload model.pth (optional)", type=["pt", "pth"], help="If you trained a custom model, upload it here.")
    show_gradcam = st.checkbox("Enable Grad-CAM visualization", value=True)
    show_probs = st.checkbox("Show class probabilities", value=True)

# If user uploaded a model file, write to a temp file and pass path to loader
model_path = None
if upload_model is not None:
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".pth")
    tfile.write(upload_model.getvalue())
    tfile.flush()
    model_path = tfile.name

model = load_model_from_path(model_path=model_path, num_classes=int(num_classes))

# Image uploader (accept .dcm as well)
uploaded = st.file_uploader("Upload an X-ray image or DICOM (.dcm)", type=["png","jpg","jpeg","dcm"])
if uploaded is None:
    st.info("Upload a chest X-ray image (jpg/png) or a DICOM (.dcm) file to run prediction.")
else:
    try:
        filename = uploaded.name.lower()
        if filename.endswith(".dcm"):
            img = dicom_bytes_to_pil(uploaded.getvalue())
        else:
            img = Image.open(io.BytesIO(uploaded.getvalue())).convert("RGB")

        st.image(img, caption="Uploaded image", use_column_width=True)

        # Preprocess and predict
        input_tensor = transform(img).unsqueeze(0)  # shape (1,C,H,W)
        with torch.no_grad():
            outputs = model(input_tensor)
            probs = torch.softmax(outputs, dim=1)[0]
            pred_class = torch.argmax(probs).item()

        class_names = [f"Class_{i}" for i in range(int(num_classes))]
        # If two classes, give nicer default labels
        if int(num_classes) == 2:
            class_names = ["Normal","Pneumonia"]

        if show_probs:
            st.subheader("Prediction")
            st.write(f"**{class_names[pred_class]}** â€” {probs[pred_class].item()*100:.2f}% confidence")
            # Bar chart (simple)
            chart_data = {class_names[i]: float(probs[i].item()) for i in range(len(probs))}
            st.bar_chart(pd.DataFrame.from_dict(chart_data, orient="index", columns=["probability"]))

        # Grad-CAM
        if show_gradcam:
            if not GRADCAM_AVAILABLE:
                st.error("pytorch-grad-cam is not installed in this environment. Add it to requirements.txt or set .streamlit/runtime.txt to a compatible Python version.")
                st.exception(gradcam_import_error)
            else:
                # select target layer depending on model wrapper
                try:
                    if hasattr(model, "model"):  # ResNetClassifier wrapper
                        target_layers = [model.model.layer4[-1]]
                    else:
                        target_layers = [model.layer4[-1]]
                    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=False)
                    rgb_img = np.array(img.resize((224,224))) / 255.0
                    grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(pred_class)])[0]
                    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)
                    st.subheader("Grad-CAM")
                    st.image(visualization, caption="Grad-CAM visualization", use_column_width=True)
                except Exception as e:
                    st.error(f"Grad-CAM failed: {e}")

    except Exception as e:
        st.error(f"Failed to process uploaded file: {e}")
